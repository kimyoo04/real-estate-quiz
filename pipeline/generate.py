"""
CertiPass AI Pipeline â€” Generate quiz JSON from exam text.

Usage:
    python generate.py input/sample_realtor_2023.txt
    python generate.py input/sample_realtor_2023.txt --output output/ch_1_quiz.json
    python generate.py input/sample_realtor_2023.txt --copy-to-frontend
"""

import argparse
import json
import shutil
import sys
from pathlib import Path

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from schemas import QuizOutput

load_dotenv()

SYSTEM_PROMPT = """\
ë‹¹ì‹ ì€ í•œêµ­ êµ­ê°€ê³µì¸ìê²©ì¦ ì‹œí—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ê¸°ì¶œë¬¸ì œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‘ ê°€ì§€ ìœ í˜•ì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ê·œì¹™

### ê°ê´€ì‹ ë¬¸ì œ (multiple_choice)
- ì›ë³¸ ê¸°ì¶œë¬¸ì œë¥¼ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ë³´ê¸°(options)ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
- correctIndexëŠ” 0ë¶€í„° ì‹œì‘í•˜ëŠ” ì¸ë±ìŠ¤ì…ë‹ˆë‹¤ (ì •ë‹µì´ 1ë²ˆì´ë©´ 0, 5ë²ˆì´ë©´ 4).
- í•´ì„¤ì€ ì›ë¬¸ í•´ì„¤ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.

### ë¹ˆì¹¸ ëš«ê¸° (fill_in_the_blank)
- [í•µì‹¬ ìš”ì•½] ì„¹ì…˜ì˜ ë¬¸ì¥ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
- ê° ë¬¸ì¥ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œ í•˜ë‚˜ë¥¼ [BLANK]ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
- answerì—ëŠ” ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ ì •í™•í•œ ë‹¨ì–´/êµ¬ë¥¼ ë„£ìŠµë‹ˆë‹¤.
- ë¹ˆì¹¸ì„ ì±„ìš°ë©´ ì™„ì „í•œ ë¬¸ì¥ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
- [BLANK]ëŠ” ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

### ID ê·œì¹™
- ê°ê´€ì‹: q_001, q_002, ... ìˆœì„œëŒ€ë¡œ
- ë¹ˆì¹¸: ê°ê´€ì‹ ì´í›„ ë²ˆí˜¸ë¥¼ ì´ì–´ì„œ (ì˜ˆ: ê°ê´€ì‹ 4ê°œë©´ ë¹ˆì¹¸ì€ q_005ë¶€í„°)
"""

USER_PROMPT = """\
ë‹¤ìŒ ê¸°ì¶œë¬¸ì œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ JSON ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

---
{exam_text}
---
"""


def load_input(path: str) -> str:
    """Load exam text from file."""
    text = Path(path).read_text(encoding="utf-8")
    if not text.strip():
        print(f"Error: Input file is empty: {path}", file=sys.stderr)
        sys.exit(1)
    return text


def generate_quiz(exam_text: str, model_name: str = "gpt-4o-mini") -> QuizOutput:
    """Run LangChain structured output pipeline."""
    llm = ChatOpenAI(model=model_name, temperature=0)
    structured_llm = llm.with_structured_output(QuizOutput)

    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        ("human", USER_PROMPT),
    ])

    chain = prompt | structured_llm
    result = chain.invoke({"exam_text": exam_text})
    return result


def to_json_list(quiz: QuizOutput) -> list[dict]:
    """Convert QuizOutput to the flat JSON array format expected by frontend."""
    items = []
    for mc in quiz.multiple_choice:
        items.append(mc.model_dump())
    for fb in quiz.fill_in_the_blank:
        items.append(fb.model_dump())
    return items


def main():
    parser = argparse.ArgumentParser(description="Generate quiz JSON from exam text")
    parser.add_argument("input", help="Path to input exam text file")
    parser.add_argument("--output", "-o", help="Output JSON file path")
    parser.add_argument(
        "--copy-to-frontend",
        action="store_true",
        help="Also copy output to public/data/ for frontend use",
    )
    parser.add_argument(
        "--model",
        default="gpt-4o-mini",
        help="OpenAI model to use (default: gpt-4o-mini)",
    )
    args = parser.parse_args()

    # Load input
    print(f"ğŸ“– Loading: {args.input}")
    exam_text = load_input(args.input)

    # Parse metadata from text
    lines = exam_text.strip().split("\n")
    meta = {}
    for line in lines[:10]:
        if ":" in line:
            key, val = line.split(":", 1)
            meta[key.strip()] = val.strip()

    print(f"ğŸ“‹ ìê²©ì¦: {meta.get('ìê²©ì¦', '?')}")
    print(f"ğŸ“‹ ê³¼ëª©: {meta.get('ê³¼ëª©', '?')}")
    print(f"ğŸ“‹ ë‹¨ì›: {meta.get('ë‹¨ì›', '?')}")
    print(f"ğŸ¤– Model: {args.model}")
    print("â³ Generating quiz data...")

    # Generate
    quiz = generate_quiz(exam_text, model_name=args.model)

    print(f"âœ… Generated: {len(quiz.multiple_choice)} multiple choice, "
          f"{len(quiz.fill_in_the_blank)} fill-in-the-blank")

    # Convert to frontend format
    json_data = to_json_list(quiz)

    # Determine output path
    output_path = args.output
    if not output_path:
        Path("output").mkdir(exist_ok=True)
        output_path = "output/quiz_output.json"

    # Write output
    Path(output_path).write_text(
        json.dumps(json_data, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    print(f"ğŸ’¾ Saved: {output_path}")

    # Optionally copy to frontend
    if args.copy_to_frontend:
        frontend_path = Path(__file__).parent.parent / "public" / "data"
        if frontend_path.exists():
            dest = frontend_path / "realtor" / "sub_1" / "ch_1_quiz.json"
            dest.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(output_path, dest)
            print(f"ğŸ“¦ Copied to frontend: {dest}")
        else:
            print("âš ï¸  Frontend public/data/ not found, skipping copy")

    # Preview
    print("\n--- Preview (first 2 items) ---")
    for item in json_data[:2]:
        print(json.dumps(item, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
